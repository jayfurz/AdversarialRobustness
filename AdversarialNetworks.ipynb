{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLY4xsBNOCba",
        "outputId": "52c6cd8f-653a-4bb1-9c3a-f25fec910e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 184MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load a pre-trained VGG model\n",
        "vgg_model = models.vgg16(pretrained=True).to(device)\n",
        "\n",
        "# We will use the features up to the second max pooling layer of the VGG model\n",
        "# Create a new Sequential module containing the desired layers\n",
        "vgg_feature_extractor = nn.Sequential(*list(vgg_model.features)[:9]).to(device)\n",
        "# Calculate the correct input dimensions for the first fully connected layer after the VGG feature extractor\n",
        "with torch.no_grad():\n",
        "    # Use the same dummy input size as your training images\n",
        "    dummy_input = torch.randn(1, 3, 32, 32, device=device)  # Example for CIFAR-10\n",
        "    dummy_output = vgg_feature_extractor(dummy_input)\n",
        "    # Flatten the output to calculate the total number of flat features\n",
        "    flat_features = int(torch.flatten(dummy_output).shape[0])\n",
        "\n",
        "# Set the VGG model to evaluation mode\n",
        "vgg_feature_extractor.eval()\n",
        "\n",
        "# Freeze the parameters of the feature extractor to prevent training\n",
        "for param in vgg_feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Simple Convolutional Neural Network Model Definition\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.num_classes = num_classes  # Added this attribute\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class TRADESCNN(SimpleCNN):\n",
        "    def __init__(self, num_classes, beta):\n",
        "        super(TRADESCNN, self).__init__(num_classes)\n",
        "        self.beta = beta\n",
        "\n",
        "    # Implement the TRADES adversarial training within the loss function\n",
        "    def forward(self, x):\n",
        "        return super(TRADESCNN, self).forward(x)\n",
        "\n",
        "    def calculate_loss(self, model_output, target, optimizer, x_natural, x_adv):\n",
        "        criterion_natural = nn.CrossEntropyLoss()\n",
        "        criterion_robust = nn.KLDivLoss(reduction='batchmean')\n",
        "        loss_natural = criterion_natural(model_output, target)\n",
        "        loss_robust = criterion_robust(F.log_softmax(x_adv, dim=1), F.softmax(x_natural, dim=1))\n",
        "        loss = loss_natural + self.beta * loss_robust\n",
        "        return loss\n",
        "\n",
        "# Perceptual Adversarial Training (PAT) Model Definition\n",
        "class PATCNN(SimpleCNN):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(PATCNN, self).__init__(num_classes=num_classes)\n",
        "        self.feature_extractor = vgg_feature_extractor\n",
        "        self.fc1 = nn.Linear(flat_features, 120)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract perceptual features and pass them through the rest of the network\n",
        "        perceptual_features = self.feature_extractor(x)\n",
        "        x = perceptual_features.view(perceptual_features.size(0), -1)  # Flatten the features\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x, perceptual_features\n",
        "\n",
        "# RoBal Model Definition\n",
        "class RoBalCNN(SimpleCNN):\n",
        "    def __init__(self, num_classes=10, dataset=None):\n",
        "        super(RoBalCNN, self).__init__(num_classes=num_classes)\n",
        "        self.class_weights = self.calculate_class_weights(dataset)\n",
        "\n",
        "    def calculate_class_weights(self, dataset):\n",
        "        # This function will calculate the weight for each class based on the\n",
        "        # inverse frequency of the classes in the dataset provided.\n",
        "        # If dataset is None or not provided, default equal weights are used.\n",
        "        if dataset is None:\n",
        "            return torch.ones(self.num_classes)\n",
        "\n",
        "        class_counts = torch.zeros(self.num_classes)\n",
        "        for _, target in dataset:\n",
        "            class_counts[target] += 1\n",
        "\n",
        "        # Use inverse frequency to determine class weights\n",
        "        # Adding 1 to avoid division by zero for classes not present in the dataset\n",
        "        class_weights = 1.0 / (class_counts + 1.0)\n",
        "\n",
        "        # Normalize weights such that they sum to the number of classes\n",
        "        class_weights = self.num_classes * class_weights / class_weights.sum()\n",
        "        return class_weights.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return super(RoBalCNN, self).forward(x)\n",
        "\n",
        "    def compute_loss(self, outputs, targets):\n",
        "        # This function is an example where the loss function is given\n",
        "        # additional class weights computed from the dataset. It should\n",
        "        # be used in place of the typical criterion during training.\n",
        "        return F.cross_entropy(outputs, targets, weight=self.class_weights)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and DataLoader setup\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainloader_cifar10 = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader_cifar10 = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "trainloader_cifar100 = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testloader_cifar100 = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform),\n",
        "    batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# ImageNet dataset is large and not directly accessible; the code below is a placeholder\n",
        "# trainloader_imagenet = torch.utils.data.DataLoader(...)\n",
        "# testloader_imagenet = torch.utils.data.DataLoader(...)\n",
        "\n",
        "# Training and testing on CIFAR-10 for SimpleCNN\n",
        "net_cifar10 = SimpleCNN(num_classes=10).to(device)\n",
        "# Training and testing on CIFAR-100 for SimpleCNN\n",
        "net_cifar100 = SimpleCNN(num_classes=100).to(device)\n",
        "# Assuming there are 10 classes for the custom model and the `beta` is initialized with a random example value of 1.0.\n",
        "net_trades_cifar10 = TRADESCNN(num_classes=10, beta=1.0).to(device)\n",
        "# Instantiate the PATCNN model as well.\n",
        "net_pat_cifar10 = PATCNN(num_classes=10).to(device)\n",
        "# Instantiate the RoBalCNN model for CIFAR-10.\n",
        "net_robal_cifar10 = RoBalCNN(num_classes=10, dataset=trainloader_cifar10.dataset).to(device)\n",
        "\n",
        "\n",
        "# Define a function for training\n",
        "def train(net, trainloader, epochs):\n",
        "    net.to(device)\n",
        "    net.train()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:\n",
        "                print(f'[Epoch {epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "# Define a function for testing\n",
        "# Define a function for testing\n",
        "def test(net, testloader):\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            # If the network's forward function returns multiple outputs, we take the first one\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def evaluate_robustness(net, testloader, epsilon=0.05):\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Add a small perturbation to the images\n",
        "        perturbed_images = images + epsilon * torch.randn_like(images)\n",
        "        perturbed_images = torch.clamp(perturbed_images, 0, 1)  # Ensure it's still a valid image\n",
        "        outputs = net(perturbed_images)\n",
        "        if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    robustness_accuracy = correct / total\n",
        "    return robustness_accuracy\n",
        "\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    \"\"\"\n",
        "    Carries out FGSM attack to create adversarial examples.\n",
        "\n",
        "    Args:\n",
        "    image (Tensor): Original image.\n",
        "    epsilon (float): Step size (perturbation amount).\n",
        "    data_grad (Tensor): Gradient of the loss with respect to the input image.\n",
        "\n",
        "    Returns:\n",
        "    perturbed_image (Tensor): Adversarial image.\n",
        "    \"\"\"\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image\n",
        "\n",
        "\n",
        "def train_with_adversarial(net, trainloader, epsilon, epochs):\n",
        "    \"\"\"\n",
        "    Trains a neural network with adversarial examples using FGSM.\n",
        "\n",
        "    Args:\n",
        "    net (nn.Module): Neural network model.\n",
        "    trainloader (DataLoader): DataLoader for training data.\n",
        "    epsilon (float): Strength of the adversarial perturbation.\n",
        "    epochs (int): Number of epochs to train for.\n",
        "    \"\"\"\n",
        "    net.train()  # Make sure the network is in training mode\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Tell PyTorch to track gradients for the inputs\n",
        "            inputs.requires_grad = True\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to calculate predictions and loss\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Get the gradients for the input data to generate adversarial examples\n",
        "            data_grad = inputs.grad.data\n",
        "\n",
        "            # Create adversarial examples using the FGSM method\n",
        "            perturbed_data = fgsm_attack(inputs, epsilon, data_grad)\n",
        "\n",
        "            # Re-classify the perturbed images\n",
        "            outputs_perturbed = net(perturbed_data)\n",
        "            loss_perturbed = criterion(outputs_perturbed, labels)\n",
        "\n",
        "            # Zero the parameter gradients again before the backward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate gradients for the perturbed data\n",
        "            loss_perturbed.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print statistics\n",
        "            if i % 1000 == 999:  # Print every 1000 mini-batches\n",
        "                print(f'[Epoch {epoch + 1}, Mini-batch {i + 1}] loss: {loss.item():.3f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecaflr0piG0",
        "outputId": "e95fb458-5f1e-48dd-edd6-3bdb8e9e7fca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_TRADES(net, trainloader, epsilon, beta, epochs):\n",
        "    net.train()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Tell PyTorch to track gradients for the inputs\n",
        "            inputs.requires_grad_(True)\n",
        "\n",
        "            # Forward pass to compute the loss on clean inputs\n",
        "            outputs_clean = net(inputs)\n",
        "            loss_clean = criterion(outputs_clean, labels)\n",
        "\n",
        "            # Compute gradients with respect to inputs for adversarial example creation\n",
        "            optimizer.zero_grad()\n",
        "            loss_clean.backward(retain_graph=True)  # Keep the graph for the next backward pass\n",
        "            inputs_grad = inputs.grad.data.clone()  # Clone the gradients to avoid them being overwritten\n",
        "\n",
        "            # Zero the gradients for the next pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Generate adversarial examples using the perturbed inputs with collected gradients\n",
        "            perturbed_inputs = fgsm_attack(inputs, epsilon, inputs_grad)\n",
        "\n",
        "            # Forward pass on the adversarial examples and compute the loss\n",
        "            outputs_adv = net(perturbed_inputs)\n",
        "            loss_adv = criterion(outputs_adv, labels)  # Cross-entropy loss for adversarial examples\n",
        "\n",
        "            # Calculate the classification loss on the clean outputs\n",
        "            outputs_clean_detached = outputs_clean.detach()  # Detach the clean outputs\n",
        "            loss_kl = F.kl_div(\n",
        "                F.log_softmax(outputs_adv, dim=1),\n",
        "                F.softmax(outputs_clean_detached, dim=1),\n",
        "                reduction='batchmean'\n",
        "            ) * beta  # Include the TRADES beta parameter\n",
        "\n",
        "            # Combine the classification loss and regularization term into a single scalar\n",
        "            loss_combined = loss_adv + loss_kl\n",
        "\n",
        "            # Backward pass and optimize based on the combined loss\n",
        "            loss_combined.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 2000 == 0:\n",
        "                print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {loss_combined.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_PAT(net, trainloader, epsilon, alpha, epochs):\n",
        "    net.train()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            inputs.requires_grad_(True)\n",
        "\n",
        "            # Forward pass to calculate predictions and extract features\n",
        "            outputs_clean, features_clean = net(inputs)\n",
        "            loss_clean = criterion(outputs_clean, labels)\n",
        "\n",
        "            # Calculate gradients for adversarial example generation\n",
        "            loss_clean.backward(retain_graph=True)\n",
        "            inputs_grad = inputs.grad.data\n",
        "            inputs.grad.zero_()\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            perturbed_inputs = fgsm_attack(inputs, epsilon, inputs_grad)\n",
        "\n",
        "            # Forward pass with adversarial examples\n",
        "            outputs_adv, features_adv = net(perturbed_inputs)\n",
        "            loss_adv = criterion(outputs_adv, labels)\n",
        "\n",
        "            # Calculate PAT loss (perceptual similarity term)\n",
        "            perceptual_loss = F.pairwise_distance(features_clean, features_adv).mean()\n",
        "\n",
        "            # Combined loss\n",
        "            loss = loss_clean + alpha * perceptual_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 1000 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(trainloader)}], PAT Loss: {loss.item():.4f}')\n",
        "\n",
        "def train_RoBal(net, trainloader, epsilon, epochs):\n",
        "    net.train()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            inputs.requires_grad_(True)\n",
        "\n",
        "            # Calculate weighted loss on clean inputs\n",
        "            outputs_clean = net(inputs)\n",
        "            loss_clean = net.compute_loss(outputs_clean, labels)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate gradients for clean inputs\n",
        "            loss_clean.backward(retain_graph=True)\n",
        "            inputs_grad = inputs.grad.data\n",
        "\n",
        "            # Zero the gradients after backward pass to start clean for adversarial example generation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Generate adversarial examples\n",
        "            perturbed_inputs = fgsm_attack(inputs, epsilon, inputs_grad)\n",
        "\n",
        "            # Calculate weighted loss on adversarial examples\n",
        "            outputs_adv = net(perturbed_inputs)\n",
        "            loss_adv = net.compute_loss(outputs_adv, labels)\n",
        "\n",
        "            # Combine losses\n",
        "            loss_combined = loss_clean + loss_adv\n",
        "\n",
        "            # Backward pass and optimize based on the combined loss\n",
        "            loss_combined.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 1000 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(trainloader)}], Loss: {loss_combined.item():.4f}')"
      ],
      "metadata": {
        "id": "yULhN42vfTHo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the epsilon for FGSM\n",
        "epsilon = 0.1\n",
        "\n",
        "# Training and testing on CIFAR-10\n",
        "net_cifar10 = SimpleCNN(num_classes=10)\n",
        "train(net_cifar10, trainloader_cifar10, epochs=1)\n",
        "accuracy_cifar10 = test(net_cifar10, testloader_cifar10)\n",
        "robustness_accuracy = evaluate_robustness(net_cifar10, testloader_cifar10, epsilon=epsilon)\n",
        "print(f'Accuracy of the network on the CIFAR-10 test images: {accuracy_cifar10 * 100}%')\n",
        "print(f'Accuracy on the adversarial set without adversarial training: {robustness_accuracy * 100: .2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g9T-eVg2twx",
        "outputId": "e8acb877-93ae-4091-bacd-b64a31a98a20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, 2000] loss: 2.132\n",
            "[Epoch 1, 4000] loss: 1.803\n",
            "[Epoch 1, 6000] loss: 1.612\n",
            "[Epoch 1, 8000] loss: 1.521\n",
            "[Epoch 1, 10000] loss: 1.478\n",
            "[Epoch 1, 12000] loss: 1.417\n",
            "Accuracy of the network on the CIFAR-10 test images: 50.09%\n",
            "Accuracy on the adversarial set without adversarial training:  26.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network with adversarial examples\n",
        "train_with_adversarial(net_cifar10, trainloader_cifar10, epsilon, epochs=1)\n",
        "\n",
        "# Evaluate the accuracy and robustness of the trained model\n",
        "accuracy = test(net_cifar10, testloader_cifar10)\n",
        "robustness_accuracy = evaluate_robustness(net_cifar10, testloader_cifar10, epsilon=epsilon)\n",
        "\n",
        "print(f'Accuracy on the test set: {accuracy * 100: .2f}%')\n",
        "print(f'Accuracy on the adversarial set: {robustness_accuracy * 100: .2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY7ML7Yy45k9",
        "outputId": "2729c4ad-9f45-4949-f83a-dc27771a5760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Mini-batch 1000] loss: 1.326\n",
            "[Epoch 1, Mini-batch 2000] loss: 1.178\n",
            "[Epoch 1, Mini-batch 3000] loss: 1.806\n",
            "[Epoch 1, Mini-batch 4000] loss: 1.927\n",
            "[Epoch 1, Mini-batch 5000] loss: 1.648\n",
            "[Epoch 1, Mini-batch 6000] loss: 1.488\n",
            "[Epoch 1, Mini-batch 7000] loss: 3.133\n",
            "[Epoch 1, Mini-batch 8000] loss: 2.493\n",
            "[Epoch 1, Mini-batch 9000] loss: 3.194\n",
            "[Epoch 1, Mini-batch 10000] loss: 5.941\n",
            "[Epoch 1, Mini-batch 11000] loss: 4.743\n",
            "[Epoch 1, Mini-batch 12000] loss: 8.086\n",
            "Accuracy on the test set:  26.80%\n",
            "Accuracy on the adversarial set:  37.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running on CIFAR-100 and ImageNet\n",
        "Only run the following block if you want to train using the larger datasets.\n",
        "\n",
        "## CIFAR-100 (Not used due to runtime constraints):\n",
        "Similar in size to CIFAR-10 but with 100 classes containing 600 images each. It can also be obtained through torchvision.\n",
        "## ImageNet (Not used due to runtime constraints):\n",
        "A large visual database designed for use in visual object recognition research, with more than 14 million images categorized according to the WordNet hierarchy. ImageNet is not directly included in PyTorch's datasets, but it can be accessed following the instructions at http://www.image-net.org/.\n",
        "\n",
        "Please note that due to the computational resources required, we limited our study to one epoch training on the CIFAR-10 dataset. The complete multi-epoch training across all datasets, including CIFAR-100 and ImageNet, is part of future work."
      ],
      "metadata": {
        "id": "JT1a26Yz25AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing on CIFAR-100\n",
        "net_cifar100 = SimpleCNN(num_classes=100)\n",
        "train(net_cifar100, trainloader_cifar100, epochs=1)\n",
        "accuracy_cifar100 = test(net_cifar100, testloader_cifar100)\n",
        "print(f'Accuracy of the network on the CIFAR-100 test images: {accuracy_cifar100 * 100}%')\n",
        "\n",
        "# Training and testing on ImageNet (Placeholder)\n",
        "net_imagenet = SimpleCNN(num_classes=1000)  # Assuming 1000 classes for ImageNet\n",
        "train(net_imagenet, trainloader_imagenet, epochs=1)\n",
        "accuracy_imagenet = test(net_imagenet, testloader_imagenet)\n",
        "print(f'Accuracy of the network on the ImageNet test images: {accuracy_imagenet * 100}%')"
      ],
      "metadata": {
        "id": "bqFUZk9z2yjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the individual CNNs\n",
        "We will train the CNN instances with different adversarial methods."
      ],
      "metadata": {
        "id": "aBlE8L8p5oS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For TRADES training\n",
        "epsilon = 0.1  # FGSM perturbation strength\n",
        "beta = 1.0     # TRADES beta hyperparameter\n",
        "epochs = 1     # Number of epochs to train for\n",
        "train_TRADES(net_trades_cifar10, trainloader_cifar10, epsilon, beta, epochs)\n",
        "\n",
        "# Testing the models' accuracy and robustness would be the same as before\n",
        "accuracy_trades = test(net_trades_cifar10, testloader_cifar10)\n",
        "print(f'Accuracy of TRADES on the test set: {accuracy_trades * 100: .2f}%')\n",
        "\n",
        "robustness_accuracy_trades = evaluate_robustness(net_trades_cifar10, testloader_cifar10, epsilon=epsilon)\n",
        "print(f'Accuracy of TRADES on the adversarial set: {robustness_accuracy_trades * 100: .2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GHlAbyHfj0h",
        "outputId": "21a6dfef-0b42-43cb-80fd-69d7dfefb6ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [2000/12500], Loss: 2.2979\n",
            "Epoch [1/1], Step [4000/12500], Loss: 2.2732\n",
            "Epoch [1/1], Step [6000/12500], Loss: 1.9542\n",
            "Epoch [1/1], Step [8000/12500], Loss: 2.1338\n",
            "Epoch [1/1], Step [10000/12500], Loss: 2.6021\n",
            "Epoch [1/1], Step [12000/12500], Loss: 2.9948\n",
            "Accuracy of TRADES on the test set:  14.44%\n",
            "Accuracy of TRADES on the adversarial set:  17.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_pat_cifar10 = PATCNN(num_classes=10).to(device)\n",
        "\n",
        "# For PAT training\n",
        "alpha = 1.5    # PAT alpha hyperparameter\n",
        "train_PAT(net_pat_cifar10, trainloader_cifar10, epsilon, alpha, epochs)\n",
        "\n",
        "accuracy_pat = test(net_pat_cifar10, testloader_cifar10)\n",
        "print(f'Accuracy of PAT on CIFAR-10 test images: {accuracy_pat * 100:.2f}%')\n",
        "\n",
        "robustness_accuracy_PAT = evaluate_robustness(net_pat_cifar10, testloader_cifar10, epsilon=epsilon)\n",
        "print(f'Robustness of PAT on perturbed CIFAR-10 images: {robustness_accuracy_PAT * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUO3ShPqM6Y",
        "outputId": "00f892ea-40b9-4c5a-fed5-041c046ba768"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [1000/12500], PAT Loss: 7.1570\n",
            "Epoch [1/1], Step [2000/12500], PAT Loss: 6.0433\n",
            "Epoch [1/1], Step [3000/12500], PAT Loss: 8.7731\n",
            "Epoch [1/1], Step [4000/12500], PAT Loss: 7.0780\n",
            "Epoch [1/1], Step [5000/12500], PAT Loss: 8.0055\n",
            "Epoch [1/1], Step [6000/12500], PAT Loss: 6.6488\n",
            "Epoch [1/1], Step [7000/12500], PAT Loss: 7.1328\n",
            "Epoch [1/1], Step [8000/12500], PAT Loss: 5.6037\n",
            "Epoch [1/1], Step [9000/12500], PAT Loss: 7.6323\n",
            "Epoch [1/1], Step [10000/12500], PAT Loss: 8.2173\n",
            "Epoch [1/1], Step [11000/12500], PAT Loss: 6.4723\n",
            "Epoch [1/1], Step [12000/12500], PAT Loss: 3.9811\n",
            "Accuracy of PAT on CIFAR-10 test images: 44.38%\n",
            "Robustness of PAT on perturbed CIFAR-10 images: 22.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RoBalCNN with adversarial examples\n",
        "train_RoBal(net_robal_cifar10, trainloader_cifar10, epsilon, epochs)\n",
        "\n",
        "\n",
        "accuracy_robal_cifar10 = test(net_robal_cifar10, testloader_cifar10)\n",
        "print(f'Accuracy of RoBalCNN on CIFAR-10 test images: {accuracy_robal_cifar10 * 100:.2f}%')\n",
        "\n",
        "robustness_robal_cifar10 = evaluate_robustness(net_robal_cifar10, testloader_cifar10, epsilon)\n",
        "print(f'Robustness of RoBalCNN on perturbed CIFAR-10 images: {robustness_robal_cifar10 * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myp1r5omgY9N",
        "outputId": "40c42ad6-6db9-47c7-b825-f98f63aff7f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [1000/12500], Loss: 4.6588\n",
            "Epoch [1/1], Step [2000/12500], Loss: 3.8909\n",
            "Epoch [1/1], Step [3000/12500], Loss: 4.2004\n",
            "Epoch [1/1], Step [4000/12500], Loss: 4.0785\n",
            "Epoch [1/1], Step [5000/12500], Loss: 2.9427\n",
            "Epoch [1/1], Step [6000/12500], Loss: 3.5142\n",
            "Epoch [1/1], Step [7000/12500], Loss: 2.8668\n",
            "Epoch [1/1], Step [8000/12500], Loss: 3.2341\n",
            "Epoch [1/1], Step [9000/12500], Loss: 3.3158\n",
            "Epoch [1/1], Step [10000/12500], Loss: 3.9952\n",
            "Epoch [1/1], Step [11000/12500], Loss: 3.1770\n",
            "Epoch [1/1], Step [12000/12500], Loss: 2.5586\n",
            "Accuracy of RoBalCNN on CIFAR-10 test images: 45.48%\n",
            "Robustness of RoBalCNN on perturbed CIFAR-10 images: 34.26%\n"
          ]
        }
      ]
    }
  ]
}